{"cells":[{"cell_type":"markdown","metadata":{},"source":["This notebook was used as reference in my project.\n","\n","This notebook was taken from [kaggle](https://www.kaggle.com/code/matanivanov/wide-deep-learning-for-recsys-with-pytorch/notebook)"]},{"cell_type":"markdown","metadata":{},"source":["# Wide and Deep Learning for RecSys with Pytorch"]},{"cell_type":"markdown","metadata":{},"source":["This notebook was inspired by \"Wide & Deep Learning for Recommender Systems\" [paper](https://arxiv.org/pdf/1606.07792.pdf) by Google. In this paper authors propose an interesting NN arcitecture for Recommender Systems  \n","![](https://miro.medium.com/max/875/1*1jA7Qt71aMK_qG89tfUOoA.png)  \n","I was strugguling to find realization of this arcitecture, so I decided to implement my own using Pytorch"]},{"cell_type":"markdown","metadata":{},"source":["# Data loading"]},{"cell_type":"markdown","metadata":{},"source":["The data which I choose for implementing this architecture is Movie Lens 100k dataset. It has some key advantages:\n","- Popular. I bet you are already know or at leats hear about it\n","- Simple. Just user rates for number of movies and a bit of meta information\n","- Variative. It allows to construct binary features like previous watched films as long as some continious features important for deep part of network\n","- Small size. It has only 100K rates and limited number of users and features, so the traing part won\\`t take to long \n","\n","And also one major drawback:\n","- Tre dataset has no information to generate cross-product of userinstalled apps and impression apps as in original paper"]},{"cell_type":"markdown","metadata":{},"source":["**The data consist of:**  \n","Information about when and how user rated a movie"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T21:19:59.18171Z","iopub.status.busy":"2021-11-26T21:19:59.181344Z","iopub.status.idle":"2021-11-26T21:19:59.298057Z","shell.execute_reply":"2021-11-26T21:19:59.29731Z","shell.execute_reply.started":"2021-11-26T21:19:59.181678Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","\n","#Load the Ratings data\n","data = pd.read_csv('../input/movielens-100k-dataset/ml-100k/u.data', sep=\"\\t\", header=None)\n","data.columns = ['user id', 'movie id', 'rating', 'timestamp']\n","data.head()"]},{"cell_type":"markdown","metadata":{},"source":["Additional information about each user such as age, gender, occupation and zip code"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T21:19:59.300045Z","iopub.status.busy":"2021-11-26T21:19:59.299786Z","iopub.status.idle":"2021-11-26T21:19:59.319971Z","shell.execute_reply":"2021-11-26T21:19:59.319247Z","shell.execute_reply.started":"2021-11-26T21:19:59.30002Z"},"trusted":true},"outputs":[],"source":["#Load the User data\n","users = pd.read_csv('../input/movielens-100k-dataset/ml-100k/u.user', \n","                    sep=\"|\", encoding='latin-1', header=None)\n","users.columns = ['user id', 'age', 'gender', 'occupation', 'zip code']\n","users.head()"]},{"cell_type":"markdown","metadata":{},"source":["Additional information about movie such as title, release date and genre"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T21:19:59.321941Z","iopub.status.busy":"2021-11-26T21:19:59.321468Z","iopub.status.idle":"2021-11-26T21:19:59.362089Z","shell.execute_reply":"2021-11-26T21:19:59.361278Z","shell.execute_reply.started":"2021-11-26T21:19:59.321906Z"},"trusted":true},"outputs":[],"source":["#Load movie data\n","items = pd.read_csv('../input/movielens-100k-dataset/ml-100k/u.item', \n","                    sep=\"|\", encoding='latin-1', header=None)\n","items.columns = ['movie id', 'movie title' ,'release date','video release date', 'IMDb URL', \n","                 'unknown', 'Action', 'Adventure', 'Animation', 'Children\\'s', 'Comedy', \n","                 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', \n","                 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n","items.head()"]},{"cell_type":"markdown","metadata":{},"source":["The list of all genres represented in dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T21:19:59.363859Z","iopub.status.busy":"2021-11-26T21:19:59.363344Z","iopub.status.idle":"2021-11-26T21:19:59.37984Z","shell.execute_reply":"2021-11-26T21:19:59.379004Z","shell.execute_reply.started":"2021-11-26T21:19:59.363823Z"},"trusted":true},"outputs":[],"source":["GENRES = pd.read_csv('../input/movielens-100k-dataset/ml-100k/u.genre', \n","                     sep=\"|\", header=None, usecols=[0])[0].tolist()\n","GENRES"]},{"cell_type":"markdown","metadata":{},"source":["# EDA"]},{"cell_type":"markdown","metadata":{},"source":["Let\\`s take look at data a bit closer"]},{"cell_type":"markdown","metadata":{},"source":["There are total 943 users and 1682 movies"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T21:23:16.808047Z","iopub.status.busy":"2021-11-26T21:23:16.807737Z","iopub.status.idle":"2021-11-26T21:23:16.813406Z","shell.execute_reply":"2021-11-26T21:23:16.812508Z","shell.execute_reply.started":"2021-11-26T21:23:16.80802Z"},"trusted":true},"outputs":[],"source":["print(\n","    (f\"Number of users: {users['user id'].nunique()}\\n\" \n","    f\"Nuber of movies: {items['movie id'].nunique()}\")\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Movies are often rated as 3 or 4 stars from five"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T21:19:59.392558Z","iopub.status.busy":"2021-11-26T21:19:59.391944Z","iopub.status.idle":"2021-11-26T21:19:59.560744Z","shell.execute_reply":"2021-11-26T21:19:59.559887Z","shell.execute_reply.started":"2021-11-26T21:19:59.392521Z"},"trusted":true},"outputs":[],"source":["data['rating'].value_counts().sort_index().plot.bar()"]},{"cell_type":"markdown","metadata":{},"source":["The users are mostly aged from 20 to 30"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T21:19:59.562586Z","iopub.status.busy":"2021-11-26T21:19:59.562035Z","iopub.status.idle":"2021-11-26T21:20:00.416139Z","shell.execute_reply":"2021-11-26T21:20:00.415326Z","shell.execute_reply.started":"2021-11-26T21:19:59.562547Z"},"trusted":true},"outputs":[],"source":["users['age'].value_counts().sort_index().plot.bar(figsize=(12, 8))"]},{"cell_type":"markdown","metadata":{},"source":["There are more than to male users for each female in this dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T21:20:00.417828Z","iopub.status.busy":"2021-11-26T21:20:00.417498Z","iopub.status.idle":"2021-11-26T21:20:00.537819Z","shell.execute_reply":"2021-11-26T21:20:00.536971Z","shell.execute_reply.started":"2021-11-26T21:20:00.417791Z"},"trusted":true},"outputs":[],"source":["users['gender'].value_counts().plot.bar()"]},{"cell_type":"markdown","metadata":{},"source":["Not suprizingly the most popular occupatation for so young users is student"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T21:20:00.540895Z","iopub.status.busy":"2021-11-26T21:20:00.540559Z","iopub.status.idle":"2021-11-26T21:20:00.784407Z","shell.execute_reply":"2021-11-26T21:20:00.783494Z","shell.execute_reply.started":"2021-11-26T21:20:00.540866Z"},"trusted":true},"outputs":[],"source":["users['occupation'].value_counts().plot.bar()"]},{"cell_type":"markdown","metadata":{},"source":["# Features and target"]},{"cell_type":"markdown","metadata":{},"source":["It\\`s time to define a target for this data. I choose to predict next watched movie. Also I use user mean rate as a feature"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T21:20:00.787199Z","iopub.status.busy":"2021-11-26T21:20:00.786842Z","iopub.status.idle":"2021-11-26T21:20:00.866127Z","shell.execute_reply":"2021-11-26T21:20:00.865444Z","shell.execute_reply.started":"2021-11-26T21:20:00.78716Z"},"trusted":true},"outputs":[],"source":["dataset = data.sort_values(['user id', 'timestamp']).reset_index(drop=True)\n","dataset['one'] = 1\n","dataset['sample_num'] = dataset.groupby('user id')['one'].cumsum()\n","\n","dataset['target'] = dataset.groupby('user id')['movie id'].shift(-1)\n","dataset['mean_rate'] = dataset.groupby('user id')['rating'].cumsum() / dataset['sample_num']\n","\n","dataset.head()"]},{"cell_type":"markdown","metadata":{},"source":["The next kind of features I need for wide and deep architecture is \"user history\" features, so I keep the list of previously watched films for every new film that user rated"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T21:20:00.867727Z","iopub.status.busy":"2021-11-26T21:20:00.867378Z","iopub.status.idle":"2021-11-26T21:20:02.879998Z","shell.execute_reply":"2021-11-26T21:20:02.879243Z","shell.execute_reply.started":"2021-11-26T21:20:00.867697Z"},"trusted":true},"outputs":[],"source":["dataset['prev movies'] = dataset['movie id'].apply(lambda x: str(x))\n","dataset['prev movies'] = dataset.groupby('user id')['prev movies'].apply(lambda x: (x + ' ').cumsum().str.strip())\n","dataset['prev movies'] = dataset['prev movies'].apply(lambda x: x.split())\n","dataset.head()"]},{"cell_type":"markdown","metadata":{},"source":["And also I need continious features. Firstly I use movie meta information to generate features like user mean rate by genre and share of user watched movies by genre"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T21:20:02.883131Z","iopub.status.busy":"2021-11-26T21:20:02.882456Z","iopub.status.idle":"2021-11-26T21:20:03.195477Z","shell.execute_reply":"2021-11-26T21:20:03.194645Z","shell.execute_reply.started":"2021-11-26T21:20:02.883091Z"},"trusted":true},"outputs":[],"source":["dataset = dataset.merge(items[['movie id'] + GENRES], on='movie id', how='left')\n","for genre in GENRES:\n","    dataset[f'{genre}_rate'] = dataset[genre]*dataset['rating']\n","    dataset[genre] = dataset.groupby('user id')[genre].cumsum()\n","    dataset[f'{genre}_rate'] = dataset.groupby('user id')[f'{genre}_rate'].cumsum() / dataset[genre]\n","\n","dataset[GENRES] = dataset[GENRES].apply(lambda x: x / dataset['sample_num'])\n","dataset.head()"]},{"cell_type":"markdown","metadata":{},"source":["Secondly I use user meta information to generate features gender and one-hot encoded occupation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T21:20:03.19718Z","iopub.status.busy":"2021-11-26T21:20:03.196846Z","iopub.status.idle":"2021-11-26T21:20:03.393194Z","shell.execute_reply":"2021-11-26T21:20:03.392485Z","shell.execute_reply.started":"2021-11-26T21:20:03.197145Z"},"trusted":true},"outputs":[],"source":["dataset = dataset.merge(users, on='user id', how='left')\n","dataset['gender'] = (dataset['gender'] == 'M').astype(int)\n","dataset = pd.concat([dataset.drop('occupation', axis=1), pd.get_dummies(dataset['occupation'])], axis=1)\n","dataset.drop('other', axis=1, inplace=True)\n","dataset.drop('zip code', axis=1, inplace=True)\n","dataset.head()"]},{"cell_type":"markdown","metadata":{},"source":["Finaly I transform list of previous watched films to sparse format. For that I use scipy COO matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T21:20:03.394938Z","iopub.status.busy":"2021-11-26T21:20:03.394599Z","iopub.status.idle":"2021-11-26T21:20:03.400688Z","shell.execute_reply":"2021-11-26T21:20:03.399779Z","shell.execute_reply.started":"2021-11-26T21:20:03.394903Z"},"trusted":true},"outputs":[],"source":["def get_coo_indexes(lil):\n","    rows = []\n","    cols = []\n","    for i, el in enumerate(lil):\n","        if type(el)!=list:\n","            el = [el]\n","        for j in el:\n","            rows.append(i)\n","            cols.append(j)\n","    return rows, cols"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T21:20:03.402426Z","iopub.status.busy":"2021-11-26T21:20:03.401904Z","iopub.status.idle":"2021-11-26T21:20:03.519077Z","shell.execute_reply":"2021-11-26T21:20:03.518367Z","shell.execute_reply.started":"2021-11-26T21:20:03.402367Z"},"trusted":true},"outputs":[],"source":["from scipy.sparse import coo_matrix\n","import numpy as np\n","\n","def get_sparse_features(series, shape):\n","    coo_indexes = get_coo_indexes(series.tolist())\n","    sparse_df = coo_matrix((np.ones(len(coo_indexes[0])), (coo_indexes[0], coo_indexes[1])), shape=shape)\n","    return sparse_df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T21:20:03.520755Z","iopub.status.busy":"2021-11-26T21:20:03.52034Z","iopub.status.idle":"2021-11-26T21:20:09.545909Z","shell.execute_reply":"2021-11-26T21:20:09.545016Z","shell.execute_reply.started":"2021-11-26T21:20:03.520713Z"},"trusted":true},"outputs":[],"source":["get_sparse_features(dataset['prev movies'], (len(dataset), dataset['movie id'].max()+1))"]},{"cell_type":"markdown","metadata":{},"source":["# Data split"]},{"cell_type":"markdown","metadata":{},"source":["There is train test split in data provided by authors. But I won\\`t use it because it ignores timestamp. Otherwize I split data based on time label"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T21:20:09.548768Z","iopub.status.busy":"2021-11-26T21:20:09.548269Z","iopub.status.idle":"2021-11-26T21:20:09.553293Z","shell.execute_reply":"2021-11-26T21:20:09.552381Z","shell.execute_reply.started":"2021-11-26T21:20:09.548728Z"},"trusted":true},"outputs":[],"source":["COLD_START_TRESH = 5\n","TEST_SIZE = 0.2"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T21:20:09.554912Z","iopub.status.busy":"2021-11-26T21:20:09.554548Z","iopub.status.idle":"2021-11-26T21:20:09.623199Z","shell.execute_reply":"2021-11-26T21:20:09.622338Z","shell.execute_reply.started":"2021-11-26T21:20:09.554873Z"},"trusted":true},"outputs":[],"source":["filtred_data = dataset[(dataset['sample_num'] >= COLD_START_TRESH) &\n","                       ~(dataset['target'].isna())].sort_values('timestamp')\n","train_data = filtred_data[:int(len(filtred_data)*(1-TEST_SIZE))]\n","test_data = filtred_data[int(len(filtred_data)*(1-TEST_SIZE)):]\n","train_data.shape, test_data.shape"]},{"cell_type":"markdown","metadata":{},"source":["Let`s look how was the data splited between train and test"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T21:20:09.625157Z","iopub.status.busy":"2021-11-26T21:20:09.6248Z","iopub.status.idle":"2021-11-26T21:20:09.648433Z","shell.execute_reply":"2021-11-26T21:20:09.647499Z","shell.execute_reply.started":"2021-11-26T21:20:09.625121Z"},"trusted":true},"outputs":[],"source":["pd.concat([data['user id'].value_counts().describe(),\n","           train_data['user id'].value_counts().describe(),\n","           test_data['user id'].value_counts().describe()],\n","         axis=1,\n","         keys=['total', 'train', 'test'])"]},{"cell_type":"markdown","metadata":{},"source":["We have at least 5 films for each user in train. Movie count distribution in train reflects movie count distribution in total dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T21:20:09.65056Z","iopub.status.busy":"2021-11-26T21:20:09.650181Z","iopub.status.idle":"2021-11-26T21:20:09.905345Z","shell.execute_reply":"2021-11-26T21:20:09.904492Z","shell.execute_reply.started":"2021-11-26T21:20:09.650523Z"},"trusted":true},"outputs":[],"source":["for df in [data, train_data, test_data]:\n","    df.groupby('user id')['movie id'].count().plot.hist(bins=20)"]},{"cell_type":"markdown","metadata":{},"source":["All but 71 movies present in train data. So it won\\`t be possible to recommend them"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T21:25:41.795114Z","iopub.status.busy":"2021-11-26T21:25:41.794792Z","iopub.status.idle":"2021-11-26T21:25:41.804607Z","shell.execute_reply":"2021-11-26T21:25:41.803441Z","shell.execute_reply.started":"2021-11-26T21:25:41.795074Z"},"trusted":true},"outputs":[],"source":["print((\n","    f\"Total movies: {data['movie id'].nunique()}\\n\"\n","    f\"Movies in train: {train_data['movie id'].nunique()}\\n\"\n","    f\"Movies in test: {test_data['movie id'].nunique()}\\n\"\n","))  "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T21:20:09.918506Z","iopub.status.busy":"2021-11-26T21:20:09.917826Z","iopub.status.idle":"2021-11-26T21:20:15.847277Z","shell.execute_reply":"2021-11-26T21:20:15.844758Z","shell.execute_reply.started":"2021-11-26T21:20:09.918466Z"},"trusted":true},"outputs":[],"source":["X_train = train_data.drop(['user id', 'movie id', 'rating', 'timestamp', 'one', 'sample_num', 'target', 'prev movies'],\n","                          axis=1)\n","prev_movies_train = get_sparse_features(train_data['prev movies'], (len(train_data), dataset['movie id'].max()+1))\n","y_train = train_data['target']\n","\n","X_test = test_data.drop(['user id', 'movie id', 'rating', 'timestamp', 'one', 'sample_num', 'target', 'prev movies'],\n","                        axis=1)\n","prev_movies_test = get_sparse_features(test_data['prev movies'], (len(test_data), dataset['movie id'].max()+1))\n","y_test = test_data['target']"]},{"cell_type":"markdown","metadata":{},"source":["## Simple basline"]},{"cell_type":"markdown","metadata":{},"source":["I use multiclass LightGBM model with no parameters tuning as a baseline"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T19:46:27.000222Z","iopub.status.busy":"2021-11-26T19:46:26.999818Z","iopub.status.idle":"2021-11-26T19:53:23.15337Z","shell.execute_reply":"2021-11-26T19:53:23.152525Z","shell.execute_reply.started":"2021-11-26T19:46:27.000172Z"},"trusted":true},"outputs":[],"source":["import lightgbm as lgb\n","\n","params = {\n","    'objective': 'softmax',\n","    'num_class': items['movie id'].nunique() + 1,\n","    'num_iterations': 10,\n","    'verbose': -1\n","}\n","train_data = lgb.Dataset(X_train.reset_index(drop=True), label=y_train, free_raw_data=False)\n","movies_data_train = lgb.Dataset(prev_movies_train, free_raw_data=False)\n","train_data = train_data.construct()\n","movies_data_train = movies_data_train.construct()\n","train_data = train_data.add_features_from(movies_data_train)\n","model = lgb.train(params, train_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T19:53:23.155142Z","iopub.status.busy":"2021-11-26T19:53:23.154794Z","iopub.status.idle":"2021-11-26T19:53:34.949997Z","shell.execute_reply":"2021-11-26T19:53:34.949327Z","shell.execute_reply.started":"2021-11-26T19:53:23.155105Z"},"trusted":true},"outputs":[],"source":["test_data = lgb.Dataset(X_test.reset_index(drop=True), free_raw_data=False)\n","movies_data_test = lgb.Dataset(prev_movies_test, free_raw_data=False)\n","test_data = test_data.construct()\n","movies_data_test = movies_data_test.construct()\n","test_data = test_data.add_features_from(movies_data_test)\n","preds_baseline = model.predict(test_data.get_data())\n","preds_baseline.shape"]},{"cell_type":"markdown","metadata":{},"source":["## The Wide and Deep architecture"]},{"cell_type":"markdown","metadata":{},"source":["Finaly, let\\`s get to the wide and deep network architecture\n","  \n","In the original paper the cross-product of user installed apps and impression apps. As long as we don\\`t have any impressions working with movie lens data I use only information about previous watched filmes as features for wide component"]},{"cell_type":"markdown","metadata":{},"source":["I need to define two functions:\n","- First sparse_to_idx helps me to convert indexes of previous watched movies to series of films indexes. Also I pad this data with zeroes so I can later use it in embedding layer\n","- Second is reverse to first idx_to_sparse helps me to convert target with index of movie to series of all zeros and one in place of index. I will use it later"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T19:53:34.954898Z","iopub.status.busy":"2021-11-26T19:53:34.953191Z","iopub.status.idle":"2021-11-26T19:53:34.961779Z","shell.execute_reply":"2021-11-26T19:53:34.961131Z","shell.execute_reply.started":"2021-11-26T19:53:34.954863Z"},"trusted":true},"outputs":[],"source":["def sparse_to_idx(data, pad_idx=-1):\n","    indexes = data.nonzero()\n","    indexes_df = pd.DataFrame()\n","    indexes_df['rows'] = indexes[0]\n","    indexes_df['cols'] = indexes[1]\n","    mdf = indexes_df.groupby('rows').apply(lambda x: x['cols'].tolist())\n","    max_len = mdf.apply(lambda x: len(x)).max()\n","    return mdf.apply(lambda x: pd.Series(x + [pad_idx] * (max_len - len(x)))).values"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T19:53:34.965324Z","iopub.status.busy":"2021-11-26T19:53:34.96503Z","iopub.status.idle":"2021-11-26T19:53:34.976887Z","shell.execute_reply":"2021-11-26T19:53:34.97595Z","shell.execute_reply.started":"2021-11-26T19:53:34.965263Z"},"trusted":true},"outputs":[],"source":["def idx_to_sparse(idx, sparse_dim):\n","    sparse = np.zeros(sparse_dim)\n","    sparse[int(idx)] = 1\n","    return pd.Series(sparse, dtype=int)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T19:53:34.981266Z","iopub.status.busy":"2021-11-26T19:53:34.980785Z","iopub.status.idle":"2021-11-26T19:53:36.356399Z","shell.execute_reply":"2021-11-26T19:53:36.355465Z","shell.execute_reply.started":"2021-11-26T19:53:34.981236Z"},"trusted":true},"outputs":[],"source":["import torch\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'"]},{"cell_type":"markdown","metadata":{},"source":["Now I construct input tensors for network. I need three tensors:\n","- The tensor with continious features\n","- The tensor with previous wathched films as sequence of indexes to feed into embedding layer\n","- The tensor with previous wathched films as binary features"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T21:05:44.575699Z","iopub.status.busy":"2021-11-26T21:05:44.575286Z","iopub.status.idle":"2021-11-26T21:05:44.606175Z","shell.execute_reply":"2021-11-26T21:05:44.604951Z","shell.execute_reply.started":"2021-11-26T21:05:44.575614Z"},"trusted":true},"outputs":[],"source":["# Train part\n","PAD_IDX = 0\n","# tensor with continious features\n","X_train_tensor = torch.Tensor(X_train.fillna(0).values).to(device)\n","# tensor with sequence of indexes\n","movies_train_tensor = torch.sparse_coo_tensor(\n","    indices=prev_movies_train.nonzero(), \n","    values=[1]*len(prev_movies_train.nonzero()[0]),\n","    size=prev_movies_train.shape\n",").to_dense().to(device)\n","# tensor with binary features\n","movies_train_idx = torch.Tensor(\n","    sparse_to_idx(prev_movies_train, pad_idx=PAD_IDX),\n",").long().to(device)\n","# target\n","target_train = torch.Tensor(y_train.values).long().to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# tensor with continious features \n","X_test_tensor = torch.Tensor(X_test.fillna(0).values).to(device)\n","# tensor with continious features\n","movies_test_tensor = torch.sparse_coo_tensor(\n","    indices=prev_movies_test.nonzero(), \n","    values=[1]*len(prev_movies_test.nonzero()[0]),\n","    size=prev_movies_test.shape\n",").to_dense().to(device)\n","# tensor with binary features\n","movies_test_idx = torch.Tensor(\n","    sparse_to_idx(prev_movies_test, pad_idx=PAD_IDX),\n",").long().to(device)\n","# target\n","target_test = torch.Tensor(y_test.values).long().to(device)"]},{"cell_type":"markdown","metadata":{},"source":["And now define Wide and Deep architecture as a pytorch class"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T19:54:53.59511Z","iopub.status.busy":"2021-11-26T19:54:53.594753Z","iopub.status.idle":"2021-11-26T19:54:53.604818Z","shell.execute_reply":"2021-11-26T19:54:53.603946Z","shell.execute_reply.started":"2021-11-26T19:54:53.595072Z"},"trusted":true},"outputs":[],"source":["from torch import nn, cat, mean\n","\n","class WideAndDeep(nn.Module):\n","    def __init__(\n","        self, \n","        continious_feature_shape, # number of continious features\n","        embed_size, # size of embedding for binary features\n","        embed_dict_len, # number of unique binary features\n","        pad_idx # padding index\n","    ):\n","        super(WideAndDeep, self).__init__()\n","        self.embed = nn.Embedding(embed_dict_len, embed_size, padding_idx=pad_idx)\n","        self.linear_relu_stack = nn.Sequential(\n","            nn.Linear(embed_size + continious_feature_shape, 1024),\n","            nn.ReLU(),\n","            nn.Linear(1024, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 256),\n","            nn.ReLU()\n","        )\n","        self.head = nn.Sequential(\n","            nn.Linear(embed_dict_len + 256, embed_dict_len),\n","        )\n","\n","    def forward(self, continious, binary, binary_idx):\n","        # get embeddings for sequence of indexes\n","        binary_embed = self.embed(binary_idx)\n","        binary_embed_mean = mean(binary_embed, dim=1)\n","        # get logits for \"deep\" part: continious features + binary embeddings\n","        deep_logits = self.linear_relu_stack(cat((continious, binary_embed_mean), dim=1))\n","        # get final softmax logits for \"deep\" part and raw binary features\n","        total_logits = self.head(cat((deep_logits, binary), dim=1))\n","        return total_logits"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T19:54:53.60651Z","iopub.status.busy":"2021-11-26T19:54:53.606152Z","iopub.status.idle":"2021-11-26T19:54:53.669999Z","shell.execute_reply":"2021-11-26T19:54:53.669135Z","shell.execute_reply.started":"2021-11-26T19:54:53.606472Z"},"trusted":true},"outputs":[],"source":["model = WideAndDeep(\n","    X_train.shape[1], \n","    16, \n","    items['movie id'].nunique() + 1, \n","    PAD_IDX\n",").to(device)\n","print(model)"]},{"cell_type":"markdown","metadata":{},"source":["Let\\`s train the network"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T19:54:53.672008Z","iopub.status.busy":"2021-11-26T19:54:53.671647Z","iopub.status.idle":"2021-11-26T19:55:01.643218Z","shell.execute_reply":"2021-11-26T19:55:01.64173Z","shell.execute_reply.started":"2021-11-26T19:54:53.671971Z"},"trusted":true},"outputs":[],"source":["EPOCHS = 10\n","loss_fn = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","\n","for t in range(EPOCHS):\n","    model.train()\n","    pred_train = model(X_train_tensor, movies_train_tensor, movies_train_idx)\n","    loss_train = loss_fn(pred_train, target_train)\n","\n","    # Backpropagation\n","    optimizer.zero_grad()\n","    loss_train.backward()\n","    optimizer.step()\n","\n","    model.eval()\n","    with torch.no_grad():\n","        pred_test = model(X_test_tensor, movies_test_tensor, movies_test_idx)\n","        loss_test = loss_fn(pred_test, target_test)\n","    \n","    print(f\"Epoch {t}\")\n","    print(f\"Train loss: {loss_train:>7f}\")\n","    print(f\"Test loss: {loss_test:>7f}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Compare metrics"]},{"cell_type":"markdown","metadata":{},"source":["To ensure Wide and Deep network is capable of solving recommendation task I compare it with baseline"]},{"cell_type":"markdown","metadata":{},"source":["The first metric I look at is Mean Squared Error\n","  \n","As you see my implementation is twice better than baseline"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T20:12:43.692193Z","iopub.status.busy":"2021-11-26T20:12:43.691855Z","iopub.status.idle":"2021-11-26T20:12:52.280206Z","shell.execute_reply":"2021-11-26T20:12:52.279182Z","shell.execute_reply.started":"2021-11-26T20:12:43.692163Z"},"trusted":true},"outputs":[],"source":["# mse\n","from sklearn.metrics import mean_squared_error\n","\n","y_test_sparse = y_test.apply(lambda x: idx_to_sparse(x, items['movie id'].nunique() + 1))\n","mse_baseline = mean_squared_error(y_test_sparse, preds_baseline)\n","print(f'Mean squared error for baseline: {mse_baseline:.4f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T20:20:37.457552Z","iopub.status.busy":"2021-11-26T20:20:37.457153Z","iopub.status.idle":"2021-11-26T20:20:37.532437Z","shell.execute_reply":"2021-11-26T20:20:37.531579Z","shell.execute_reply.started":"2021-11-26T20:20:37.457519Z"},"trusted":true},"outputs":[],"source":["loss = nn.MSELoss()\n","softmax = nn.Softmax(dim=0)\n","mse_wnd = loss(softmax(pred_test), torch.Tensor(y_test_sparse.values).to(device)).cpu().detach().numpy()\n","print(f'Mean squared error for Wide and Deep: {mse_wnd:.4f}')"]},{"cell_type":"markdown","metadata":{},"source":["The second metric I look at is the mean rank next movie has in recommendations\n","  \n","Baseline puts it on a shy 841 place as the Wide and deep does 200 places better!"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T20:25:08.550216Z","iopub.status.busy":"2021-11-26T20:25:08.549846Z","iopub.status.idle":"2021-11-26T20:25:16.901717Z","shell.execute_reply":"2021-11-26T20:25:16.900767Z","shell.execute_reply.started":"2021-11-26T20:25:08.550182Z"},"trusted":true},"outputs":[],"source":["# mean rank\n","from scipy.stats import rankdata\n","\n","ranks = pd.DataFrame(preds_baseline).apply(lambda x: pd.Series(rankdata(-x)), axis=1)\n","ranks_target = (ranks.values * y_test_sparse).sum(axis=1)\n","mean_rank_baseline = ranks_target.mean()\n","print(f'Mean rank for baseline: {mean_rank_baseline:.0f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T20:26:05.349456Z","iopub.status.busy":"2021-11-26T20:26:05.34914Z","iopub.status.idle":"2021-11-26T20:26:14.984703Z","shell.execute_reply":"2021-11-26T20:26:14.983832Z","shell.execute_reply.started":"2021-11-26T20:26:05.349426Z"},"trusted":true},"outputs":[],"source":["preds_wnd = softmax(pred_test).cpu().detach().numpy()\n","ranks_wnd = pd.DataFrame(preds_wnd).apply(lambda x: pd.Series(rankdata(-x)), axis=1)\n","ranks_target_wnd = (ranks_wnd.values * y_test_sparse).sum(axis=1)\n","mean_rank_wnd = ranks_target_wnd.mean()\n","print(f'Mean rank for Wide and Deep: {mean_rank_wnd:.0f}')"]},{"cell_type":"markdown","metadata":{},"source":["So there is my implementatation and it seems to be working despite all limitations. Thumbs up!"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
